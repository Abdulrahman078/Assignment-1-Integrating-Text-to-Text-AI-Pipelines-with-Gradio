{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Example Notebook"
      ],
      "metadata": {
        "id": "-Ix16ey2erLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " A separate notebook that demonstrates various Gradio components. If needed,use hardcoded data to show the functionality of the Gradio components.\n"
      ],
      "metadata": {
        "id": "3dxNBkEhexES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "YlfGrVVBe16M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements\n",
        "\n",
        "Start by installing and importing necessary libraries"
      ],
      "metadata": {
        "id": "7lICoKpGe4kP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBJQeBn0YrwE"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "!pip install wget\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import wget"
      ],
      "metadata": {
        "id": "OTYay5Uge-Jw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier and Function\n",
        "Define the classifer and the sentences along with the function"
      ],
      "metadata": {
        "id": "Dx7kdVxhfQ0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classifer(sentiment-analysis)\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RwSoWhwosP3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037f5b06-a3a5-4c48-ff4d-d3fd6947233c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(filename):\n",
        "    results = []\n",
        "\n",
        "    with open(filename, \"r\") as fn:  # Removed .name if filename is a string\n",
        "        lines = fn.readlines()\n",
        "        for sentence in lines:\n",
        "            result = classifier(sentence)  # Assuming classifier is already defined\n",
        "            result = result[0]  # Extract the first result\n",
        "            results.append({\n",
        "                'Sentence': sentence.strip(),  # Strip extra whitespace/newlines\n",
        "                'Label': result['label'],\n",
        "                'Score': f\"{result['score'] * 100:.2f}%\" # We'll take the percentage score with only 2 decimal points\n",
        "            })\n",
        "\n",
        "    # Create a DataFrame from the list of results\n",
        "    df = pd.DataFrame(results)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "dGn2a4A4fQGl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio\n",
        "\n"
      ],
      "metadata": {
        "id": "IHHnKudGfFtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=sentiment_analysis, # Function used by gradio\n",
        "    inputs=gr.File(label=\"Upload a file (txt)\"), # User inputs (file)\n",
        "    outputs=gr.Dataframe(label='Results'), # Programs' output (DataFrame)\n",
        "    title='Sentiment-Analysis',\n",
        "    description=\"Simple gradio interface that illustrate the use of gradio\"\n",
        ")\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "xE3M_HFgfN4L",
        "outputId": "57682d5c-cf1b-42ea-8dae-aeda5c555bfe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://044b165add47a43780.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://044b165add47a43780.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://044b165add47a43780.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}